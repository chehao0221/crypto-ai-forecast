from __future__ import annotations

import os
import json
import warnings
import math
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo
from typing import Dict, List, Tuple

import pandas as pd
import requests
from xgboost import XGBRegressor

from utils.safe_yfinance import safe_yf_download

warnings.filterwarnings("ignore")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(BASE_DIR, ".cache")
os.makedirs(CACHE_DIR, exist_ok=True)

HISTORY_FILE = os.path.join(BASE_DIR, "crypto_history.csv")
UNIVERSE_CACHE_FILE = os.path.join(CACHE_DIR, "crypto_universe.json")

WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

MAIN_5 = ["BTC-USD", "ETH-USD", "SOL-USD", "BNB-USD", "XRP-USD"]

# ä½ åŸæœ¬çš„ universeï¼ˆä¿ç•™ï¼‰
DEFAULT_UNIVERSE = [
    "BTC-USD", "ETH-USD", "BNB-USD", "SOL-USD", "XRP-USD",
    "ADA-USD", "DOGE-USD", "AVAX-USD", "DOT-USD", "LINK-USD",
    "MATIC-USD", "LTC-USD", "BCH-USD", "ATOM-USD", "TRX-USD",
    "ETC-USD", "FIL-USD", "NEAR-USD", "APT-USD", "ARB-USD",
    "OP-USD", "SUI-USD", "INJ-USD", "AAVE-USD", "UNI-USD",
    "FTM-USD"
]

TW_TZ = ZoneInfo("Asia/Taipei")


def _now_tw() -> datetime:
    return datetime.now(TW_TZ)


def _today_tw() -> str:
    return _now_tw().strftime("%Y-%m-%d")


def _post(content: str) -> None:
    # âœ… FIX(ä¸æ”¹é¡¯ç¤º): åŸæœ¬åªç™¼ã€ä¸çœ‹å›æ‡‰ç¢¼ï¼ŒDiscord 400/404 æœƒã€Œç„¡è²å¤±æ•—ã€
    # é€™è£¡åªåŠ ä¸Š status_code æª¢æŸ¥èˆ‡ logï¼Œä¸æ”¹ä½ è¨Šæ¯å…§å®¹
    if WEBHOOK_URL:
        try:
            r = requests.post(WEBHOOK_URL, json={"content": content}, timeout=15)
            if r.status_code >= 300:
                print(f"âš ï¸ Discord ç™¼é€å¤±æ•—: {r.status_code} {r.text[:200]}")
                print(content)
        except Exception as e:
            print(f"âš ï¸ Discord ç™¼é€å¤±æ•—: {e}")
            print(content)
    else:
        print(content)


def _read_history() -> pd.DataFrame:
    cols = [
        "run_date",
        "ticker",
        "pred",
        "price_at_run",
        "sup",
        "res",
        "settle_date",
        "settle_close",
        "realized_return",
        "hit",
        "status",
        "updated_at",
    ]
    if not os.path.exists(HISTORY_FILE):
        return pd.DataFrame(columns=cols)

    df = pd.read_csv(HISTORY_FILE)
    for c in cols:
        if c not in df.columns:
            df[c] = pd.NA
    df["status"] = df["status"].fillna("pending")
    return df[cols]


def _write_history(df: pd.DataFrame) -> None:
    df.to_csv(HISTORY_FILE, index=False, encoding="utf-8")


def settle_date_plus_days(date_str: str, days: int) -> str:
    d = datetime.strptime(date_str, "%Y-%m-%d")
    return (d + timedelta(days=days)).strftime("%Y-%m-%d")


def append_today_predictions(hist: pd.DataFrame, today: str, new_rows: List[Dict]) -> pd.DataFrame:
    now_str = _now_tw().strftime("%Y-%m-%d %H:%M:%S")

    df_new = pd.DataFrame(new_rows)
    if df_new.empty:
        return hist

    df_new["run_date"] = today
    df_new["status"] = "pending"
    df_new["updated_at"] = now_str

    # é¿å…åŒæ—¥åŒ ticker é‡è¤‡
    if not hist.empty:
        keep = ~(
            (hist["run_date"].astype(str) == today)
            & (hist["ticker"].astype(str).isin(df_new["ticker"].astype(str)))
        )
        hist = hist[keep].copy()

    return pd.concat([hist, df_new], ignore_index=True)


def _load_universe_cache(today: str) -> List[str] | None:
    if not os.path.exists(UNIVERSE_CACHE_FILE):
        return None
    try:
        obj = json.loads(open(UNIVERSE_CACHE_FILE, "r", encoding="utf-8").read())
        if obj.get("date") == today and isinstance(obj.get("tickers"), list):
            return obj["tickers"]
    except Exception:
        return None
    return None


def _save_universe_cache(today: str, tickers: List[str]) -> None:
    try:
        with open(UNIVERSE_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump({"date": today, "tickers": tickers}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def get_universe(today: str) -> List[str]:
    cached = _load_universe_cache(today)
    if cached:
        return cached
    _save_universe_cache(today, DEFAULT_UNIVERSE)
    return DEFAULT_UNIVERSE


def calc_pivot(df: pd.DataFrame) -> Tuple[float, float]:
    d = df.copy().tail(20)
    lo = float(d["Low"].min()) if "Low" in d.columns else float(d["Close"].min())
    hi = float(d["High"].max()) if "High" in d.columns else float(d["Close"].max())
    return round(lo, 4), round(hi, 4)


def settle_history(today: str) -> Tuple[pd.DataFrame, str]:
    hist = _read_history()
    if hist.empty:
        return hist, ""

    if hist["settle_date"].astype(str).str.len().eq(0).all():
        return hist, ""

    pending = hist[
        (hist["status"].astype(str) == "pending")
        & (hist["settle_date"].astype(str) <= today)
        & (hist["settle_date"].astype(str).str.len() > 0)
    ]
    if pending.empty:
        return hist, ""

    tickers = sorted(pending["ticker"].astype(str).unique().tolist())
    data = safe_yf_download(tickers, period="6mo", max_chunk=60)

    settled_lines: List[str] = []
    now_str = _now_tw().strftime("%Y-%m-%d %H:%M:%S")

    for idx, row in pending.iterrows():
        t = str(row["ticker"])
        settle_date = str(row["settle_date"])

        d = data.get(t)
        if d is None or d.empty:
            continue

        d2 = d.copy()
        d2.index = pd.to_datetime(d2.index).strftime("%Y-%m-%d")
        if settle_date not in d2.index:
            continue

        settle_close = float(d2.loc[settle_date, "Close"])
        try:
            price_at_run = float(row["price_at_run"])
        except Exception:
            price_at_run = float("nan")

        # âœ… FIX(ä¸æ”¹é¡¯ç¤º): é˜²æ­¢ price_at_run=0/NaN â†’ ZeroDivisionError
        if (not math.isfinite(price_at_run)) or price_at_run <= 0:
            hist.at[idx, "status"] = "invalid"
            hist.at[idx, "updated_at"] = now_str
            continue

        if (not math.isfinite(settle_close)) or settle_close <= 0:
            hist.at[idx, "status"] = "invalid"
            hist.at[idx, "updated_at"] = now_str
            continue

        rr = (settle_close / price_at_run) - 1.0

        try:
            pred_f = float(row.get("pred", pd.NA))
        except Exception:
            pred_f = None

        hit = int(rr > 0)
        mark = "âœ…" if hit == 1 else "âŒ"

        hist.at[idx, "settle_close"] = round(settle_close, 6)
        hist.at[idx, "realized_return"] = rr
        hist.at[idx, "hit"] = hit
        hist.at[idx, "status"] = "settled"
        hist.at[idx, "updated_at"] = now_str

        if pred_f is None:
            settled_lines.append(f"â€¢ {t}: å¯¦éš› {rr:+.2%} {mark}")
        else:
            settled_lines.append(f"â€¢ {t}: é ä¼° {pred_f:+.2%} | å¯¦éš› {rr:+.2%} {mark}")

    msg = "\n".join(settled_lines[:10])
    if len(settled_lines) > 10:
        msg += f"\nâ€¦ å¦å¤–é‚„æœ‰ {len(settled_lines) - 10} ç­†å·²çµç®—"
    return hist, msg


def last20_stats_line(hist: pd.DataFrame) -> str:
    if hist is None or hist.empty:
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    df = hist.copy()
    df = df[df["status"].astype(str) == "settled"]
    df = df[pd.to_numeric(df["realized_return"], errors="coerce").notna()]
    if df.empty:
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    tail = df.tail(20).copy()
    hit = pd.to_numeric(tail["hit"], errors="coerce")
    rr = pd.to_numeric(tail["realized_return"], errors="coerce")

    if hit.notna().sum() == 0 or rr.notna().sum() == 0:
        return "æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š--% / å¹³å‡å ±é…¬ï¼š--%"

    hit_rate = float(hit.mean())
    avg_rr = float(rr.mean())
    return f"æœ€è¿‘ 20 ç­†å‘½ä¸­ç‡ï¼š{hit_rate:.0%} / å¹³å‡å ±é…¬ï¼š{avg_rr:+.2%}"


def run() -> None:
    today = _today_tw()

    # 0) å…ˆçµç®—
    hist, settle_detail = settle_history(today)
    _write_history(hist)
    if settle_detail:
        _post("ğŸ§¾ å·²çµç®—æ­·å²ç´€éŒ„ï¼š\n" + settle_detail)

    # 1) ä¸‹è¼‰è³‡æ–™
    universe = get_universe(today)
    data = safe_yf_download(universe, period="2y", max_chunk=60)

    feats = ["mom20", "bias", "vol_ratio"]
    results: Dict[str, Dict] = {}

    for s, df in data.items():
        if df is None or len(df) < 160:
            continue

        df = df.copy()
        if "Close" not in df.columns:
            continue

        df["mom20"] = df["Close"].pct_change(20)
        ma20 = df["Close"].rolling(20).mean()
        df["bias"] = (df["Close"] - ma20) / ma20

        # âœ… FIX(ä¸æ”¹é¡¯ç¤º): Volume å¸¸æœ‰ NaNï¼ŒåŸæœ¬ df.dropna() æœƒæŠŠæ•´å€‹å¹£æ¸…ç©º â†’ results æ°¸é ç©º
        # åªåšã€Œå¿…è¦æ¬„ä½ã€dropnaï¼Œä¸¦ç”¨ ffill é¿å…é›¶æ˜Ÿ NaN å®³æ•´æ¢æ²’è³‡æ–™
        df["vol_ratio"] = (
            df["Volume"] / df["Volume"].rolling(20).mean()
        ).replace([math.inf, -math.inf], pd.NA).ffill()

        df["target"] = df["Close"].shift(-5) / df["Close"] - 1

        df = df.dropna(subset=["mom20", "bias", "vol_ratio", "target"])
        if len(df) < 120:
            continue

        train = df.iloc[:-1]

        model = XGBRegressor(
            n_estimators=300,
            max_depth=3,
            learning_rate=0.05,
            subsample=0.9,
            colsample_bytree=0.9,
            reg_lambda=1.0,
            random_state=42,
        )
        model.fit(train[feats], train["target"])

        pred = float(model.predict(df[feats].iloc[-1:])[0])
        sup, res = calc_pivot(df)

        price = float(df["Close"].iloc[-1])
        price_disp = round(price, 4) if price < 10 else round(price, 2)

        results[s] = {
            "pred": pred,
            "price": price_disp,
            "sup": sup,
            "res": res,
        }

    if not results:
        _post("âš ï¸ ä»Šæ—¥ç„¡å¯ç”¨çµæœï¼ˆå¯èƒ½è³‡æ–™ä¸è¶³æˆ–æŠ“å–å¤±æ•—ï¼‰")
        return

    top = sorted(results.items(), key=lambda kv: kv[1]["pred"], reverse=True)[:5]

    # 3) å¯«å…¥ historyï¼ˆä»Šæ—¥ Top5ï¼‰
    new_rows = []
    for t, r in top:
        settle_date = settle_date_plus_days(today, 5)

        # âœ… FIX(ä¸æ”¹é¡¯ç¤º): ä¸æŠŠ 0/NaN å¯«é€² historyï¼Œé¿å…æœªä¾†çµç®—å†é™¤ä»¥ 0
        try:
            _p = float(r.get("price"))
        except Exception:
            _p = float("nan")
        if (not math.isfinite(_p)) or _p <= 0:
            continue

        new_rows.append(
            {
                "ticker": t,
                "pred": r["pred"],
                "price_at_run": _p,
                "sup": r["sup"],
                "res": r["res"],
                "settle_date": settle_date,
                "settle_close": pd.NA,
                "realized_return": pd.NA,
                "hit": pd.NA,
            }
        )

    hist = append_today_predictions(hist, today, new_rows)
    _write_history(hist)

    stats_line = last20_stats_line(hist)

    # 4) Discord é¡¯ç¤ºï¼ˆé€™æ®µå®Œå…¨ä¿ç•™ä½ åŸæœ¬çš„é¡¯ç¤ºæ–¹å¼ï¼‰
    msg = f"â‚¿ åŠ å¯†è²¨å¹£ AI é€²éšé æ¸¬å ±å‘Š ({today})\n"
    msg += "-" * 42 + "\n\n"

    msg += "ğŸ† AI æµ·é¸ Top 5 (æ½›åŠ›å¹£)\n"
    medals = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ“ˆ", "ğŸ“ˆ"]
    for i, (t, r) in enumerate(top):
        msg += f"{medals[i]} {t}: é ä¼° {r['pred']:+.2%}\n"
        msg += f" â”” ç¾åƒ¹: {r['price']} (æ”¯æ’: {r['sup']} / å£“åŠ›: {r['res']})\n"

    msg += "\nğŸ’ æŒ‡å®šä¸»æµå¹£ç›£æ§ (å›ºå®šé¡¯ç¤º)\n"
    for t in MAIN_5:
        if t not in results:
            continue
        r = results[t]
        msg += f"â€¢ {t}: é ä¼° {r['pred']:+.2%} | ç¾åƒ¹ {r['price']}\n"

    msg += "\n" + stats_line
    _post(msg)


if __name__ == "__main__":
    run()
